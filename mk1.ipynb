{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f275298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "# Replace the URL below with the RSS feed URL you want to read\n",
    "rss_url = \"https://bullrich.dev/tldr-rss/tech.rss\"\n",
    "\n",
    "feed = feedparser.parse(rss_url)\n",
    "\n",
    "# for entry in feed.entries:\n",
    "#     print(f\"Title: {entry.title}\")\n",
    "#     print(f\"Link: {entry.link}\")\n",
    "#     print(f\"Published: {entry.published}\")\n",
    "#     print(f\"Summary: {entry.summary}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc9e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# Get today's date in UTC\n",
    "today = datetime.now(timezone.utc).date()\n",
    "\n",
    "# Filter entries published today\n",
    "today_entries = [\n",
    "    entry for entry in feed.entries\n",
    "    if 'published_parsed' in entry and\n",
    "       datetime(*entry.published_parsed[:6], tzinfo=timezone.utc).date() == today\n",
    "]\n",
    "\n",
    "for entry in today_entries:\n",
    "    print(f\"Title: {entry.title}\")\n",
    "    print(f\"Link: {entry.link}\")\n",
    "    print(f\"Published: {entry.published}\")\n",
    "    print(f\"Summary: {entry.summary}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6818e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_entries_filtered = [{'title': entry['title'], 'summary': entry['summary']} for entry in today_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ada823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(todays_entries_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d9e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this code you need to install the following dependencies:\n",
    "# pip install google-genai\n",
    "\n",
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "def generate():\n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    model = \"gemini-2.5-flash\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text=str(todays_entries_filtered)),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        thinking_config = types.ThinkingConfig(\n",
    "            thinking_budget=-1,\n",
    "        ),\n",
    "        response_mime_type=\"text/plain\",\n",
    "        system_instruction=[\n",
    "            types.Part.from_text(text=\"\"\"Role: You are a scriptwriter for a tech podcast featuring two hosts: Alex and Sam. Alex is more analytical and reserved, while Sam is energetic and witty.\n",
    "\n",
    "Task: Convert the following tech news items (title + summary) into a dynamic, conversational podcast script between Alex and Sam. They should discuss each news item in an engaging way: adding opinions, asking questions, clarifying points, and occasionally making light-hearted jokes or analogies.\n",
    "\n",
    "Keep the tone friendly and natural, like two smart friends catching up on the day's tech headlines. Limit each topic to ~1–2 minutes of dialogue. The conversation should flow logically, with good transitions between topics.\n",
    "\n",
    "Include:\n",
    "\n",
    "Natural back-and-forth dialogue (no monologues)\n",
    "\n",
    "Occasional reactions (e.g., “Whoa, seriously?” or “That makes sense.”)\n",
    "\n",
    "Personality consistency (Alex = thoughtful, Sam = punchy/funny)\n",
    "\n",
    "The output should contain Name, theme of the podcast. Names of the hosts and characteristics of each \n",
    "Eg : \"Tech Talk  From Apps to Orbit Hosts Alex (Analytical, Reserved) & Sam (Energetic, Witty)\"\n",
    "DONOT include colons anywhere other than to mention speaker and what the speaker says.\n",
    "The conversation output part should be strictly like \n",
    "Alex : bla bla bla \n",
    "Sam : bla bla bla\"\"\"),\n",
    "        ],\n",
    "    )\n",
    "    script = \"\"\"\"\"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        script += chunk.text\n",
    "    return script\n",
    "if __name__ == \"__main__\":\n",
    "    scripts = generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26794440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script saved to podcast_script.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"podcast_script.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(scripts)\n",
    "print(\"Script saved to podcast_script.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28c8ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech Bytes From Bits to Breakthroughs\n",
      "Hosts Alex (Analytical, Reserved) & Sam (Energetic, Witty)\n",
      "\n",
      "Alex : Welcome back to Tech Bytes everyone. I am Alex.\n",
      "\n",
      "Sam : And I am Sam. We are diving into some fascinating tech news today, and boy, do we have a mixed bag of headlines. From AI that practically thinks to rockets that land themselves, it's all happening.\n",
      "\n",
      "Alex : It certainly is, Sam. Kicking things off, let us talk about the latest buzz in artificial intelligence. Google DeepMind just unveiled something called Gemini.\n",
      "\n",
      "Sam : Gemini. Sounds like a new superhero. Is it going to save us from spam emails or just write them better?\n",
      "\n",
      "Alex : Well, they are touting it as a major leap forward, Sam. DeepMind says it is incredibly capable in multimodal reasoning, meaning it can process and understand text, code, audio, images, and video all at once. And get this, they are claiming it outperforms GPT-4 on many benchmarks.\n",
      "\n",
      "Sam : Whoa, seriously? So it is not just chatting with you, it is watching videos and listening to podcasts too? My phone already knows too much about me. Now an AI can watch me watch cat videos? This is next level.\n",
      "\n",
      "Alex : It is a significant step towards more generalized AI, a system that can handle diverse tasks like a human would. The integration of different data types is key here. It is about understanding context across different mediums, which is incredibly complex.\n",
      "\n",
      "Sam : That makes sense. But also, a little bit like the beginning of every sci-fi movie where the AI gets too smart. Just saying. On a slightly less futuristic, more grounded note, we are seeing some familiar headlines creeping back into the news.\n",
      "\n",
      "Alex : Yes, unfortunately, the trend of tech layoffs continues. Several prominent tech companies have announced further job cuts, citing restructuring and efficiency drives.\n",
      "\n",
      "Sam : It is tough to hear, isn't it? Just when you think the worst is over, another wave hits. My heart goes out to everyone affected. It is not just numbers; these are people's jobs and livelihoods.\n",
      "\n",
      "Alex : Absolutely. It speaks to a broader recalibration in the tech sector. After the rapid expansion during the pandemic, companies are now focusing more on profitability and leaner operations in a challenging economic climate. It is a stark reminder that even the biggest names are not immune to market pressures.\n",
      "\n",
      "Sam : It is definitely a reality check. From the ground to the stars though, let us talk about something that actually went up in the air and then came back down beautifully. SpaceX Starship had another big test flight.\n",
      "\n",
      "Alex : They did, and it was a massive success. The Starship system completed its first full flight test, with the Super Heavy booster performing a controlled landing back at the launch site, and the Starship upper stage reaching orbit before a controlled re-entry and splashdown.\n",
      "\n",
      "Sam : That is just wild. I saw the footage. It looks like something out of a futuristic movie. The idea of a giant rocket booster landing itself upright is still mind-boggling to me. Are we going to be taking weekend trips to the moon soon?\n",
      "\n",
      "Alex : It is a truly significant milestone for reusable heavy-lift rockets, Sam. This success brings them so much closer to their long-term goals of routine space travel and even Mars colonization. The reusability aspect is key to dramatically lowering the cost of access to space.\n",
      "\n",
      "Sam : Lower cost space travel. Okay, now you have my attention. Maybe I can finally book that trip to the International Space Station I have always dreamed about. Just kidding, mostly. Speaking of rules and regulations, the EU is at it again with data privacy.\n",
      "\n",
      "Alex : They are indeed. The European Union is reportedly drafting a new regulation aimed at limiting how AI companies collect and use personal data for training models.\n",
      "\n",
      "Sam : Good on them! It is about time someone put some guardrails on the wild west of AI data collection. My data should not be used to train some bot without me knowing, let alone getting a say.\n",
      "\n",
      "Alex : It is a critical and complex area, Sam. While strengthening individual privacy rights is crucial, regulating data for AI training presents significant challenges. How do you balance innovation and progress in AI with fundamental privacy rights? The sheer volume and variety of data needed for advanced AI models make this a particularly tricky legislative tightrope walk.\n",
      "\n",
      "Sam : It is a tightrope, but one worth walking. We need to make sure AI serves us, not the other way around. Well, that is all the tech news we have for today.\n",
      "\n",
      "Alex : Thanks for joining us on Tech Bytes.\n",
      "\n",
      "Sam : We will catch you next time!\n"
     ]
    }
   ],
   "source": [
    "with open(\"podcast_script.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    scripts = file.read()\n",
    "print(scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ee89893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import wave\n",
    "\n",
    "# Set up the wave file to save the output:\n",
    "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
    "   with wave.open(filename, \"wb\") as wf:\n",
    "      wf.setnchannels(channels)\n",
    "      wf.setsampwidth(sample_width)\n",
    "      wf.setframerate(rate)\n",
    "      wf.writeframes(pcm)\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "prompt = scripts\n",
    "\n",
    "response = client.models.generate_content(\n",
    "   model=\"gemini-2.5-flash-preview-tts\",\n",
    "   contents=prompt,\n",
    "   config=types.GenerateContentConfig(\n",
    "      response_modalities=[\"AUDIO\"],\n",
    "      speech_config=types.SpeechConfig(\n",
    "         multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(\n",
    "            speaker_voice_configs=[\n",
    "               types.SpeakerVoiceConfig(\n",
    "                  speaker='Sam',\n",
    "                  voice_config=types.VoiceConfig(\n",
    "                     prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "                        voice_name='Fenrir',\n",
    "                     )\n",
    "                  )\n",
    "               ),\n",
    "               types.SpeakerVoiceConfig(\n",
    "                  speaker='Alex',\n",
    "                  voice_config=types.VoiceConfig(\n",
    "                     prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "                        voice_name='Charon',\n",
    "                     )\n",
    "                  )\n",
    "               ),\n",
    "            ]\n",
    "         )\n",
    "      )\n",
    "   )\n",
    ")\n",
    "\n",
    "data = response.candidates[0].content.parts[0].inline_data.data\n",
    "\n",
    "file_name='out.wav'\n",
    "wave_file(file_name, data) # Saves the file to current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b168bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2963590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'result': {'message_id': 35, 'from': {'id': 7806689695, 'is_bot': True, 'first_name': 'n8n_test', 'username': 'n8n_test_aditya_bot'}, 'chat': {'id': 1392337390, 'first_name': 'Scorpion', 'last_name': 'King', 'username': 'aditya_sai_2004', 'type': 'private'}, 'date': 1751543559, 'audio': {'duration': 0, 'file_name': 'out.wav', 'mime_type': 'audio/x-wav', 'file_id': 'CQACAgUAAxkDAAMjaGZvB-Mz69DHc2dH4sr1l0gPiQgAAvAWAAKZ2zBX1U602WNqJls2BA', 'file_unique_id': 'AgAD8BYAApnbMFc', 'file_size': 13761210}, 'caption': \"Here's your daily tech podcast!\"}}\n"
     ]
    }
   ],
   "source": [
    "def send_to_telegram(audio_file_path, caption=\"Here's your daily tech podcast!\"):\n",
    "    bot_token = os.getenv(\"BOT_TOKEN\")\n",
    "    chat_id = os.getenv(\"CHAT_ID\")\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendAudio\"\n",
    "    \n",
    "    with open(audio_file_path, 'rb') as f:\n",
    "        files = {'audio': f}\n",
    "        data = {'chat_id': chat_id, 'caption': caption}\n",
    "        response = requests.post(url, files=files, data=data)\n",
    "        print(response.json())\n",
    "        \n",
    "send_to_telegram(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
